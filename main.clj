;In collaboration with Will Argus

;Problem 1: 
(def moby-word-tokens '(CALL me Ishmael . Some years ago never mind
  how long precisely having little or no money in my purse , and
  nothing particular to interest me on shore , I thought I would
  sail about a little and see the watery part of the world . It is
  a way I have of driving off the spleen , and regulating the
  circulation . Whenever I find myself growing grim about the mouth
  whenever it is a damp , drizzly November in my soul whenever I
  find myself involuntarily pausing before coffin warehouses , and
  bringing up the rear of every funeral I meet and especially
  whenever my hypos get such an upper hand of me , that it requires
  a strong moral principle to prevent me from deliberately stepping
  into the street , and methodically knocking people's hats off
  then , I account it high time to get to sea as soon as I can .
  This is my substitute for pistol and ball . With a philosophical
  flourish Cato throws himself upon his sword I quietly take to the
  ship . There is nothing surprising in this . If they but knew it
  , almost all men in their degree , some time or other , cherish
  very nearly the same feelings toward the ocean with me .))
(defn member-of-list? [w l]
  (if (empty? l)
    false
    (if (= w (first l))
      true
      (member-of-list? w (rest l)))))

(defn get-vocabulary [word-tokens vocab]
  (if (empty? word-tokens)
    vocab
    (if (member-of-list? (first word-tokens) vocab)
      (get-vocabulary (rest word-tokens) vocab)
      (get-vocabulary (rest word-tokens) (cons (first word-tokens) vocab)))))

(def moby-vocab (get-vocabulary moby-word-tokens '()))

;Problem 2
(defn get-count-of-word [w word-tokens]
  (if (empty? word-tokens)
    0
    (if (= w (first word-tokens))
      (+ 1 (get-count-of-word w (rest word-tokens) ))
      (get-count-of-word w (rest word-tokens))
      )))

;Problem 3
(defn get-word-counts [vocab word-tokens] 
  (let [count-word (fn [w]
  (get-count-of-word w word-tokens))]
  (map count-word vocab)))

(def moby-word-frequencies (get-word-counts moby-vocab moby-word-tokens))

;Problem 4
(defn flip [p] 
  (if (< (rand 1) p)
    true
    false))
(defn normalize [params]
  (let [sum (apply + params)]
  (map (fn [x] (/ x sum)) params)))
(defn sample-categorical [outcomes params]
  (if (flip (first params))
    (first outcomes)
    (sample-categorical (rest outcomes)
             (normalize (rest params)))))
(defn create-uniform-distribution [outcomes]
  (let [num-outcomes (count outcomes)]
    (map (fn [x] (/ 1 num-outcomes))
      outcomes)))

(defn sample-uniformBOW-sentence [n vocab]
  (if (= 0 n)
    '()
    (cons (sample-categorical vocab (create-uniform-distribution vocab)) (sample-uniformBOW-sentence (- n 1) vocab)
    )
  ))

;Problem 5
(defn compute-uniform-BOW-prob [vocab sentence]
  (if (= '() sentence)
    1
    (* (/ 1 (count vocab)) (compute-uniform-BOW-prob  vocab (rest sentence)))))

;Problem 6
;Any three word sentence generated by sample-uniformBOW-sentence using moby-vocab will have the same probability. This is because every word in moby-vocab appears only once and has equal probability of (/ 1 (count moby-vocab)), in this case: 1/2744000.

;Problem 7
(def moby-word-probabilities (normalize moby-word-frequencies))

;Problem 8
(defn sample-BOW-sentence [len vocabulary probabilities]
  (if (= len 0)
    '()
    (cons (sample-categorical vocabulary probabilities)
         (sample-BOW-sentence (- len 1) vocabulary probabilities))))
;(I purse other), (their as me), (same way pistol)

;Problem 9
(defn lookup-probability [w outcomes probs] 
  (if (empty? outcomes)
    0
    (if (= w (first outcomes))
      (first probs)
      (lookup-probability w (rest outcomes) (rest probs)))))

;Problem 10
(defn product [l]
  (apply * l))
(defn compute-BOW-prob [sentence vocabulary probabilities] 
  (if (empty? sentence)
    1
      (product (concat (list (lookup-probability (first sentence) vocabulary probabilities)) (list (compute-BOW-prob (rest sentence) vocabulary probabilities))))))

;Problem 11
;(I purse other): 9/9129329
; (their as me): 10/9129329
; (same way pistol): 1/9129329
;The probabilities we get using this function can differ fairly significantly, unlike using the uniform version, where every sentence is equally likely to occur.
;If we choose the sentence (same way pistol), given that our numerator is 1, it seems likely each of these words has minimal probability. The sentence (pistol pistol pistol) also has probability 1/9129329.
;To compute the probability of a sentence under this model, we just need to know the probability of drawing each word in the sentence, and how many times each of those words appears in the sentence, the order of the words is irrelevant.